# Unified Artefact & Provenance Overview

Phase 2 Redux consolidates donors, samples, reagents, labware, instrument runs, and data products under the `app_provenance` schema. Every entity the lab needs to track becomes an **artefact**, with provenance edges describing how material moves and transforms over time. This document summarises the core concepts and captures the updated guidance agreed in the Phase 2 Redux review.

## What Makes an Artefact a “Sample”?

The previous schema elevated “samples” as a dedicated table. In the unified model a **sample** remains an artefact whose type has `kind = 'material'`, but we now distinguish three flavours:

- **Physical artefacts** are inseparable from the container well or tube they inhabit. The artefact row represents “the contents of A01 on plate XYZ” (or “tube barcode 12345”) rather than an abstract aliquot. Moving material to a different container creates a new physical artefact with a lineage edge back to the source.
- **Virtual artefacts** capture contextual or imported knowledge that is not tied to labware, e.g. manifests received from an external collaborator with donor identifiers, expected concentration, or metadata such as phenotype. These can be linked to the physical artefacts created during intake.
- **Data artefacts** model data products generated by instruments or analysis pipelines. They may describe the file payload directly or reference storage locations.

Transformations—splits, pools, amplifications—still create new artefacts linked to their parents. The difference is that a physical artefact is now synonymous with the fine-grained storage location that holds it; there is no extra table managing “sample to well” assignments.

## Artefact Basics

- `app_provenance.artefacts` holds the canonical records for physical material, digital deliverables, containers, instruments, and workflow placeholders. Each row references an `artefact_type` defining its semantics (e.g. `material_physical`, `material_virtual`, `container`, `data_product`, `subject`).
- Physical labware wells are also artefacts. Each row records its `container_artefact_id` and `container_slot_id`, while traits capture properties such as well location (`plate_position`), volume, concentration, and fragment length distribution. When a robot reports updated measurements, the same artefact row is amended (with trait history maintained) rather than updating a separate join table.
- Flexible attributes continue to live in `artefact_traits` and `artefact_trait_values`, allowing traits such as concentration, storage temperature, fragment size metrics, QC decisions, or barcode chemistry to be attached without schema churn. Trait history is versioned with `effective_at` timestamps so conflicting measurements remain visible.

Views such as `app_core.v_sample_overview` filter material artefacts to deliver the familiar sample-centric perspective for researchers, preserving the mental model while benefiting from the broader artefact framework.

## Provenance & Lineage

- `process_instances` capture each lab or informatics activity (extraction, QC, pooling, normalisation, sequencing, demultiplexing). A process references a `process_type`, tracks timing and operator metadata, and may be scoped to projects/facilities.
- `process_io` ties artefacts to processes as inputs or outputs. Roles and optional `multiplex_group` values model pooled or latent connections—e.g. multiple indexed libraries contributing to a pooled sample and later demultiplexed into per-sample data products.
- `artefact_relationships` store direct parent/child edges (split, merge, derived_from, virtual↔physical links) and link back to the originating `process_instance_id`. This accommodates both simple derivations and many-to-many graphs.

Together these structures provide a first-class provenance graph: artefacts connect to processes, which connect back to artefacts. Lineage queries in `v_sample_lineage`, `v_process_activity`, and related views traverse the graph while respecting row-level security.

## Containment & Storage

- Containers are artefacts whose type `kind` is `container`. Slot layouts (`container_slot_definitions` and `container_slots`) still describe the physical blueprint, but the slot artefacts now *are* the tracked samples. A 96-well plate therefore has 96 child artefacts (A01…H12) with their own trait sets.
- Physical and logical storage locations are modelled via `storage_nodes`, and movements are recorded in `artefact_storage_events`. Helper views (`v_artefact_current_location`, `v_storage_tree`) provide current placements and hierarchical storage paths.
- Because containers, wells, and locations all participate as artefacts, the model handles “sample in well in plate in rack in freezer” or “data product stored in S3 prefix” uniformly, while ensuring measurements, QC calls, and volume adjustments land on the correct artefact.

## Measurement & Normalisation Walkthrough

Consider a 96-well plate loaded with size-selected DNA libraries destined for normalisation:

1. **Initial state** – The plate artefact owns 96 well artefacts. Two wells are controls (negative water control and a positive commercial standard with known concentration/fragment profile); the remaining wells are physical sample artefacts for the scientific libraries. Volume, concentration, and fragment traits start as unknown for the sample wells but pre-populated for the controls.
2. **Measurement process** – A `super-DNA-quantifier` process instance consumes the plate artefact as input and emits a data-product artefact describing the instrument run. A parser updates the volume trait on each well artefact and records concentration/fragment metrics on the relevant physical sample artefacts. Conflicting readings simply generate additional trait history records; the lineage graph captures which run produced which measurement.
3. **QC decision** – A lab QC process writes a pass/fail trait on each physical sample artefact. Virtual artefacts (e.g. external manifests) remain linked so acceptance/rejection can be reconciled with upstream expectations.
4. **Normalisation** – The robot-driven normalisation process takes the measured plate, an empty destination plate (with blank well artefacts), and a buffer reagent artefact as inputs. Its data product indicates how much volume was transferred per well. The source well artefacts receive updated volume traits; the destination well artefacts become new physical sample artefacts linked back to the source via `artefact_relationships`.

At no point do we maintain a separate “sample-to-well assignment” row—the well artefact *is* the sample. Provenance edges express derivations, and the trait history captures how instruments or humans updated measurements over time.

## Access Control & Scoping

- Artefacts and processes are tagged to scopes using `artefact_scopes` and `process_scopes`. Scopes cascade permissions via the scope inheritance fabric defined in Phase 1 Redux (`app_security.scopes`, `scope_memberships`, `scope_role_inheritance`).
- RLS functions such as `app_provenance.can_access_artefact` and `app_security.actor_has_scope` ensure that researchers only observe artefacts tied to their projects or facilities. Operators and admins retain broad visibility.

PostgREST/PostGraphile expose curated views (`app_core.v_sample_overview`, `app_core.v_labware_contents`, `app_provenance.v_lineage_summary`, etc.) so front-end workflows can present persona-friendly perspectives without breaking the unified model.

## Seeded Scenarios

Migration `20251010013000_phase2_redux_seed.sql` and its follow-ups populate representative datasets used in demos and regression tests. As the schema evolves to make wells first-class artefacts the seeds will follow the same pattern, ensuring documentation and fixtures describe identical behaviour.

- **Organoid expansion** lineage covering cryopreservation, RNA/protein derivatives, and storage moves.
- **LCMS spike-in analysis** mixing participant plasma with QA reagents to illustrate converging parents and facility scopes.
- **PBMC multi-omics workflow** showing diamonds, splits, merges, and eventual sequencing data products with multiplexed provenance.
- **DNA normalisation** (new) demonstrating measurement data products, QC traits, and robot-driven transfers between plates.

Running `make db/reset` followed by `make test/security` or `make contracts/export` rebuilds the database and regenerates API contracts so the documentation stays aligned with the deployed schema.
